{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amend SQL To Work In SAS Scheduler\n",
    "\n",
    "\n",
    "SAS scheduler has its own Olive schema, but this has some limitations, the main one being:\n",
    "- It does not have its own space allocated i.e. it cannot create tables in it own schema. But it can create hash tables\n",
    "\n",
    "Therefore any existing code will need to be modified to run through SAS scheduler. Typically you will have to use hash tables whenever you can. Also any saved data will have to be stored in tables in a different schema (e.g. your own). This script helps you to:\n",
    "1. produce a list of procedures and all tables within each procedure\n",
    "2. for each proc/table you can change or add a schema\n",
    "3. for each proc/table you can add a prefix (e.g. #) \n",
    "\n",
    "\n",
    "#### The process is:\n",
    "1. Save the sql script into a text file\n",
    "2. Update the parameter settings below (e.g. file names and locations) \n",
    "3. Run Step 1: Get a list of procs and tables\n",
    "4. Look at the resulting Excel spreadsheet.\n",
    "5. Create another sheet in the same spreadsheet with the list of procs and tables and for each have a column for schema, prefix (in that order) and if replace whole. You should have 4 columns, which you need to give headers to (see below for example). Enter the schema name (if any) that you want (note if you want to keep the existing schema then you still need to enter it), any prefix (e.g. #), or if you want to replace the existing table/proc with something else entirely. Note that if there is a whole replacement then the schema and prefix fields are ignored.\n",
    "6. Run Part 2: Process SQL script with changes \n",
    "\n",
    "#### Example spreadsheet format for proc/table changes required:\n",
    "\n",
    "|Proc_Table Name                                        |    Schema         |   Prefix    | Replace Whole |\n",
    "|:------------------------------------------------------|:-----------------:|:-----------:|:-------------:|\n",
    "|cp2_accounts                                           |    thompsonja     |   SAS_      |               |\n",
    "|cp2_box_lookup                                         |                   |   #         |               |\n",
    "|vespa_analysts.channel_map_prod_service_key_attributes |    vespa_analysts |             |               |\n",
    "|('waterfall_base')                                     |                   |             | ('thompsonja.waterfall_base') |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Be Aware Of:\n",
    "\n",
    "1. \"create index i1 on tablename (xxxx)\" - the table will not be found in step 1, but will get replaced in step 2 if found through a keyword in step 1.\n",
    "2. \"execute('call procname..\" - Will miss the proc in step 1. Will be replaced in step 2 if found through a keyword in step 1\n",
    "3. Dynamic SQL may not get matched nor replaced in either step and will need to be manually changed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# folder name for all files\n",
    "folder_name = 'C:/Users/thompja/OneDrive - Sky/002 Measurement General/000 BAU Panel Balancing/02 POC SAS Scheduler/'  \n",
    "\n",
    "# text files for original and processed SQL\n",
    "sql_input_filename = 'PanBal_M02_WaterfallSQL.txt'\n",
    "sql_output_filename = 'PanBal_M02_WaterfallSQL_SAS.txt'\n",
    "\n",
    "# Spreadsheet to use for proc/table lists and schema/prefixes\n",
    "in_out_excel = 'PanBal_M02_WaterfallSQL Procs Tables.xlsx'\n",
    "# sheet that contains proc/table schema/prefixes\n",
    "sheet_name_for_settings = 'Settings'\n",
    "\n",
    "# SQL keywords to search for that are immediately before proc/table name - should be lower case\n",
    "keyword_search_list = ['procedure', 'execute', 'call', 'table', 'into', 'update', 'from', 'join', 'object_id']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def star_out_star_comments_from_sql(all_text):\n",
    "    \n",
    "    uncomment_text = all_text   \n",
    "\n",
    "    start_comment_star = -1\n",
    "    char_star_end = False\n",
    "    \n",
    "    \n",
    "    for i in range(len(uncomment_text)):\n",
    "        check_chars = uncomment_text[i : i+2]\n",
    "         \n",
    "        if check_chars == '/*':\n",
    "            start_comment_star = i       \n",
    "        elif check_chars == '*/':\n",
    "            char_star_end = True\n",
    "        \n",
    "        \n",
    "        if start_comment_star == i:\n",
    "            # at the start of the star comment so do nothing\n",
    "            pass\n",
    "        elif start_comment_star > -1 and not char_star_end:\n",
    "            # a /* has already started, and not yet reached the end\n",
    "            # so populated text with a star\n",
    "            uncomment_text = uncomment_text[: i] + '*' + uncomment_text[i+1 :]\n",
    "        elif start_comment_star and char_star_end:\n",
    "            # reached the end of a star comment\n",
    "            # so reset start_comment_star\n",
    "            start_comment_star = False        \n",
    "        else:\n",
    "            pass\n",
    "                \n",
    "    return uncomment_text      \n",
    "            \n",
    "\n",
    "def remove_dash_comments_from_sql(text_list):\n",
    "    \n",
    "    uncomment_text = text_list   \n",
    "   \n",
    "    for i in range(len(uncomment_text)):        \n",
    "        for j in range(len(uncomment_text[i])):\n",
    "            check_chars = uncomment_text[i][j : j+2]            \n",
    "            if check_chars == '--':\n",
    "                uncomment_text[i] = uncomment_text[i][ : j]                \n",
    "                break\n",
    "    \n",
    "    return uncomment_text\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def match_string_list_to_string_list(word_list, search_list):\n",
    "    # Search through the word_list to find matches to search_list\n",
    "    # Only the first x characters of each word in the word_list is compared\n",
    "    # where x is the length of the word in the search_list\n",
    "    \n",
    "    search_mask_list = [] \n",
    "\n",
    "    # Add a col for each search word and set to true if the search word has a match in the word list\n",
    "    for search_word in search_list:    \n",
    "        search_mask_list.append([x[0:len(search_word) + 1] == search_word for x in word_list])\n",
    "\n",
    "    # Transpose so that rows = each word of word_list and cols = boolean matches to the search_list\n",
    "    search_mask_array = np.asarray(search_mask_list).T\n",
    "    \n",
    "    return search_mask_array\n",
    "    \n",
    "def combine_list_into_single_string(string_list):\n",
    "    \n",
    "    combined_string = ''\n",
    "    \n",
    "    for i in range(len(string_list)):\n",
    "        combined_string += string_list[i] + '\\n'\n",
    "        \n",
    "    return combined_string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Get a list of procs and tables\n",
    "\n",
    "An Excel file will be created with the list of procs/tables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert keyword search list to an array\n",
    "keyword_search_array = np.asarray(keyword_search_list)\n",
    "\n",
    "# Read in SQL script\n",
    "sql_file = open(folder_name + sql_input_filename, 'r')\n",
    "sql_all_text = sql_file.read() # read whole text into a single variable\n",
    "sql_file.close()\n",
    "\n",
    "# turn /* comments into *  \n",
    "uncommented_sql = star_out_star_comments_from_sql(sql_all_text)\n",
    "\n",
    "# drop -- comments\n",
    "# first split by end line so can deal with '--' dash comments\n",
    "uncommented_sql = uncommented_sql.split('\\n')\n",
    "uncommented_sql = remove_dash_comments_from_sql(uncommented_sql)\n",
    "\n",
    "# recombined uncommented split list into long text\n",
    "sql_all_text = combine_list_into_single_string(uncommented_sql)\n",
    "\n",
    "\n",
    "# split by space so that we can search for key commands\n",
    "# replace tabs and spaces by end of line so text split into words\n",
    "\n",
    "# ensures there is a space before the ( to make sure the proc/table name is split out \n",
    "sql_all_text = sql_all_text.replace('(', ' (')  \n",
    "sql_all_text = sql_all_text.replace('\\t', '\\n')\n",
    "sql_all_text = sql_all_text.replace(' ', '\\n')\n",
    "sql_word_list = [x.lower() for x in sql_all_text.split('\\n')]\n",
    "\n",
    "\n",
    "# search for key words in text and set up a mask\n",
    "keyword_mask_array = match_string_list_to_string_list(sql_word_list, keyword_search_list)\n",
    "\n",
    "# if any search_list words are found then set all_keyword_mask_array to true else false (i.e. > 0 is true)\n",
    "all_keyword_mask_array = np.sum(keyword_mask_array, axis = 1)\n",
    "\n",
    "\n",
    "# loop through each word to see if any match to any key word\n",
    "# generate list of procs/tables\n",
    "keyword_find = False\n",
    "tables_and_procs = []\n",
    "latest_procedure = 'n/a'\n",
    "\n",
    "for i in range(len(all_keyword_mask_array)):\n",
    "    if all_keyword_mask_array[i] > 0:\n",
    "        keyword_find = True\n",
    "        # mask should match 1 keyword, so the 0 element of teh result will be the keyword\n",
    "        keyword = keyword_search_array[keyword_mask_array[i]][0]        \n",
    "    elif keyword_find and sql_word_list[i] != '':\n",
    "        if keyword == 'procedure':\n",
    "            # keep the name of the last procedure\n",
    "            latest_procedure = sql_word_list[i]\n",
    "        append_data = [latest_procedure, keyword, sql_word_list[i]]\n",
    "        tables_and_procs.append(append_data)\n",
    "        keyword_find = False\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " # create dataframe of proc/table lt\n",
    "tables_and_procs_df = pd.DataFrame(tables_and_procs, columns = ('Current Proc', 'Keyword', 'Table/Proc'))     \n",
    "\n",
    "# Export to Excel\n",
    "file_name_string = folder_name + in_out_excel\n",
    "\n",
    "writer = pd.ExcelWriter(file_name_string)\n",
    "tables_and_procs_df.to_excel(writer,'List_Tables_Procs')\n",
    "writer.save()\n",
    "\n",
    "# save processed script as a csv. Will read back in for Step 2.\n",
    "file_name_string = folder_name + sql_output_filename\n",
    "# Turn list into single string\n",
    "final_sql_string =  ' '.join(sql_word_list) \n",
    "text_file = open(file_name_string, \"w\")\n",
    "text_file.write(final_sql_string)\n",
    "text_file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Process SQL script with changes\n",
    "\n",
    "Before running this step you will need to enter the proc/table settings in the spreadsheet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import Excel which has proc/tables setings\n",
    "file_name_string = folder_name + in_out_excel\n",
    "table_proc_amendments_df = pd.read_excel(file_name_string, sheet_name_for_settings, index_col=None, na_values=['NA'])\n",
    "\n",
    "# import sql text processed in Step 1\n",
    "file_name_string = folder_name + sql_output_filename\n",
    "sql_file = open(file_name_string, 'r+')\n",
    "sql_all_text = sql_file.read() # read whole text into a single variable\n",
    "sql_file.close()\n",
    "\n",
    "sql_word_list = sql_all_text.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn into an array\n",
    "sql_word_array = np.asarray(sql_word_list)\n",
    "\n",
    "# loop through the proc/table list and make the changes\n",
    "for i in range(len(table_proc_amendments_df)):    \n",
    "    \n",
    "    # get the proc/table name\n",
    "    search_table_proc = table_proc_amendments_df.iloc[i,0]\n",
    "    \n",
    "    # check if there is a complete replace (NaN if not)\n",
    "    if isinstance(table_proc_amendments_df.iloc[i,3], str):\n",
    "        replace_string = table_proc_amendments_df.iloc[i,3]\n",
    "    else:\n",
    "        # not replacing whole string, so check schema and prefix        \n",
    "\n",
    "        # check if already a schema for proc/table and ignore it\n",
    "        if search_table_proc.find('.') < 0:\n",
    "            table_proc = search_table_proc\n",
    "        else:\n",
    "            table_proc = search_table_proc[search_table_proc.find('.') + 1 : ]\n",
    "\n",
    "        # check that there is a change required for proc/table (NaN if not)\n",
    "        if isinstance(table_proc_amendments_df.iloc[i,1], str):\n",
    "            schema = table_proc_amendments_df.iloc[i,1] + '.'\n",
    "        else:\n",
    "            schema = ''\n",
    "\n",
    "        # check that there is a change required for proc/table (NaN if not)\n",
    "        if isinstance(table_proc_amendments_df.iloc[i,2], str):\n",
    "            prefix = table_proc_amendments_df.iloc[i,2]\n",
    "        else:\n",
    "            prefix = ''        \n",
    "    \n",
    "        # build replacement string\n",
    "        replace_string = schema + prefix + table_proc\n",
    "    \n",
    "    \n",
    "    # find all matches to the proc/table\n",
    "    word_mask_array = np.asarray([x[0:len(search_table_proc) + 1] == search_table_proc for x in sql_word_list])\n",
    "    \n",
    "    # replace all matches with the replace string\n",
    "    sql_word_array[word_mask_array] = replace_string\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save new SQL as a text file\n",
    "final_sql_string =  ' '.join(sql_word_array)  \n",
    "\n",
    "file_name_string = folder_name + sql_output_filename\n",
    "text_file = open(file_name_string, \"w\")\n",
    "text_file.write(final_sql_string)\n",
    "text_file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
